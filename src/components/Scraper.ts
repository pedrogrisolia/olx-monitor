import * as cheerio from 'cheerio';
import fs from 'fs/promises';
import path from 'path';
import crypto from 'crypto';
import logger from './Logger';
import httpClient from './HttpClient';
import * as scraperRepository from '../repositories/scrapperRepository';
import * as notifier from './Notifier';
import Ad from './Ad';

/**
 * Limite m치ximo de an칰ncios por busca
 */
const MAX_ADS_PER_SEARCH = 500;

/**
 * Vari치veis de estado do scraper (resetadas a cada URL)
 */
let page = 1;
let maxPrice = 0;
let minPrice = 99999999;
let sumPrices = 0;
let validAds = 0;
let adsFound = 0;
let nextPage = true;
let maxAdsLimit = MAX_ADS_PER_SEARCH;
let totalOfAds: number | null = null;
let currentUrl: string = '';

let firstPageHtml: string | null = null;

/**
 * Informa칞칚o de URL para o scraper
 * Pode ser uma string simples ou objeto com metadados
 */
interface UrlInfo {
  url: string;
  userId?: number | null;
  chatId?: string | number | null;
}

/**
 * Fun칞칚o principal do scraper
 * Processa uma URL de busca do OLX e extrai an칰ncios
 * @param urlInfo URL ou objeto com URL e metadados
 */
const scraper = async (urlInfo: string | UrlInfo): Promise<void> => {
  // Reset state variables
  page = 1;
  maxPrice = 0;
  minPrice = 99999999;
  sumPrices = 0;
  adsFound = 0;
  validAds = 0;
  nextPage = true;
  maxAdsLimit = MAX_ADS_PER_SEARCH;
  totalOfAds = null;
  firstPageHtml = null;

  // Suporta tanto string simples quanto objeto
  const url = typeof urlInfo === 'string' ? urlInfo : urlInfo.url;
  const userId = typeof urlInfo === 'object' ? urlInfo.userId : null;
  const chatId = typeof urlInfo === 'object' ? urlInfo.chatId : null;

  const parsedUrl = new URL(url);
  const searchTerm = parsedUrl.searchParams.get('q') || '';
  const notify = await urlAlreadySearched(url);
  if (!notify) {
    logger.info(`First run for URL ${url} - notifications disabled`);
  } else {
    logger.info(`URL ${url} already processed - notifications enabled`);
  }

  do {
    currentUrl = setUrlParam(url, 'o', page);
    let response: string | undefined;
    try {
      response = await httpClient(currentUrl);
      if (!response) {
        logger.error('Failed to fetch URL: ' + currentUrl);
        return;
      }

      if (page === 1) {
        firstPageHtml = response;
      }

      const $ = cheerio.load(response);

      // Se n칚o existir __NEXT_DATA__, salva o HTML para an치lise (a OLX pode ter mudado ou bloqueado)
      const nextDataScript = $('script[id="__NEXT_DATA__"]').text();
      if (!nextDataScript) {
        await saveHtmlDebug(response, currentUrl, 'missing __NEXT_DATA__');
      }

      // Extrair totalOfAds apenas na primeira itera칞칚o
      if (page === 1) {
        const totalAds = extractTotalOfAds($);
        if (totalAds) {
          totalOfAds = totalAds;
          // Usa MAX_ADS_PER_SEARCH se totalOfAds for maior que o limite
          maxAdsLimit = totalAds > MAX_ADS_PER_SEARCH ? MAX_ADS_PER_SEARCH : totalAds;
          logger.info(`Total ads found: ${totalOfAds}, using limit: ${maxAdsLimit}`);

          // Notificar se for primeira execu칞칚o e houver totalOfAds
          if (!notify && totalOfAds) {
            const msg = `游댌 Foram encontrados ${totalOfAds} an칰ncios para essa busca.\n\nVoc칡 ser치 notificado sempre que aparecer novos an칰ncios ou algum an칰ncio cair de pre칞o.`;
            try {
              await notifier.sendNotification(msg, chatId);
            } catch (error) {
              logger.error('Could not send initial notification: ' + error);
            }
          }
        }
      }

      nextPage = await scrapePage($, searchTerm, notify, url, userId, chatId);

      // Se j치 na primeira p치gina n칚o encontrou resultados v치lidos e vai parar, salva HTML
      if (page === 1 && !nextPage && validAds === 0) {
        await saveHtmlDebug(response, currentUrl, 'first page returned no ads');
      }

      // Para se atingiu o limite de an칰ncios v치lidos
      if (validAds >= maxAdsLimit) {
        logger.info(`Limit of ${maxAdsLimit} valid ads reached. Stopping search.`);
        nextPage = false;
      }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error(error as Error);
      if (response) {
        await saveHtmlDebug(response, currentUrl, 'exception: ' + errorMessage);
      }
      return;
    }
    page++;
  } while (nextPage);

  logger.info('Valid ads: ' + validAds);

  // Se n칚o encontrou nenhum an칰ncio v치lido, salva o HTML da primeira p치gina para an치lise.
  if (validAds === 0 && firstPageHtml) {
    await saveHtmlDebug(firstPageHtml, setUrlParam(url, 'o', 1), 'validAds=0');
  }

  if (validAds) {
    const averagePrice = sumPrices / validAds;

    logger.info('Maximum price: ' + maxPrice);
    logger.info('Minimum price: ' + minPrice);
    logger.info('Average price: ' + sumPrices / validAds);

    const scrapperLog = {
      url,
      adsFound: validAds,
      averagePrice,
      minPrice,
      maxPrice,
    };

    await scraperRepository.saveLog(scrapperLog);
  }
};

/**
 * Salva o HTML de debug em ../data/debug, com um arquivo .json de metadados.
 * 칔til quando a OLX muda a estrutura/anti-bot e o parser para de encontrar an칰ncios.
 */
const saveHtmlDebug = async (html: string, pageUrl: string, reason: string): Promise<void> => {
  try {
    const debugDir = path.resolve(process.cwd(), '../data/debug');
    await fs.mkdir(debugDir, { recursive: true });

    const hash = crypto.createHash('sha256').update(pageUrl).digest('hex').slice(0, 12);
    const now = new Date();
    const stamp = now
      .toISOString()
      .replace(/[:.]/g, '-')
      .replace('T', '_')
      .replace('Z', '');

    const baseName = `olx-page-${stamp}-${hash}`;
    const htmlPath = path.join(debugDir, `${baseName}.html`);
    const metaPath = path.join(debugDir, `${baseName}.json`);

    await fs.writeFile(htmlPath, html, 'utf8');
    await fs.writeFile(
      metaPath,
      JSON.stringify(
        {
          savedAt: now.toISOString(),
          reason,
          pageUrl,
        },
        null,
        2
      ),
      'utf8'
    );

    logger.info(`HTML de debug salvo em: ${htmlPath}`);
  } catch (error) {
    // N칚o pode quebrar o scraper s칩 por falha de debug
    const errorMessage = error instanceof Error ? error.message : String(error);
    logger.debug('Falha ao salvar HTML de debug: ' + errorMessage);
  }
};

/**
 * Processa uma p치gina de resultados do OLX
 * @param $ Inst칙ncia do Cheerio carregada com o HTML
 * @param searchTerm Termo de busca
 * @param notify Se deve notificar sobre novos an칰ncios
 * @param url URL original da busca
 * @param userId ID do usu치rio (opcional)
 * @param chatId ID do chat para notifica칞칫es (opcional)
 * @returns true se h치 mais p치ginas, false caso contr치rio
 */
const scrapePage = async (
  $: cheerio.CheerioAPI,
  searchTerm: string,
  notify: boolean,
  url: string,
  userId: number | null = null,
  chatId: string | number | null = null
): Promise<boolean> => {
  try {
    const script = $('script[id="__NEXT_DATA__"]').text();

    if (!script) {
      return false;
    }

    const parsedData = JSON.parse(script) as {
      props: {
        pageProps: {
          ads: Array<{
            listId: number;
            subject: string;
            url: string;
            price?: string;
          }>;
        };
      };
    };

    const adList = parsedData.props.pageProps.ads;

    if (!Array.isArray(adList) || !adList.length) {
      return false;
    }

    adsFound += adList.length;

    logger.info(`Checking new ads for: ${searchTerm}`);
    logger.info('Ads found: ' + adsFound);

    for (let i = 0; i < adList.length; i++) {
      // Para se atingiu o limite de an칰ncios v치lidos
      if (validAds >= maxAdsLimit) {
        break;
      }

      logger.debug('Checking ad: ' + (i + 1));

      const advert = adList[i];
      const title = advert.subject;
      const id = advert.listId;
      const adUrl = advert.url;
      const price = parseInt(advert.price?.replace('R$ ', '')?.replace('.', '') || '0');

      const result = {
        id,
        url: adUrl,
        title,
        searchTerm,
        price,
        notify,
        userId,
        chatId,
      };

      const ad = new Ad(result);
      // IMPORTANTE: Mant칠m o comportamento original de n칚o aguardar ad.process()
      ad.process();

      if (ad.valid) {
        validAds++;
        minPrice = checkMinPrice(ad.price, minPrice);
        maxPrice = checkMaxPrice(ad.price, maxPrice);
        sumPrices += ad.price;
      }
    }

    return true;
  } catch (error) {
    logger.error(error as Error);
    throw new Error('Scraping failed');
  }
};

/**
 * Verifica se a URL j치 foi pesquisada anteriormente
 * @param url URL para verificar
 * @returns true se j치 foi pesquisada (deve notificar), false se 칠 primeira execu칞칚o
 */
const urlAlreadySearched = async (url: string): Promise<boolean> => {
  try {
    const ad = await scraperRepository.getLogsByUrl(url, 1);
    if (ad.length) {
      return true;
    }
    logger.info('First run, no notifications');
    return false;
  } catch (error) {
    logger.error(error as Error);
    return false;
  }
};

/**
 * Define um par칙metro na URL
 * @param url URL base
 * @param param Nome do par칙metro
 * @param value Valor do par칙metro
 * @returns URL modificada
 */
const setUrlParam = (url: string, param: string, value: number): string => {
  const newUrl = new URL(url);
  const searchParams = newUrl.searchParams;
  searchParams.set(param, String(value));
  newUrl.search = searchParams.toString();
  return newUrl.toString();
};

/**
 * Verifica e retorna o menor pre칞o
 */
const checkMinPrice = (price: number, currentMin: number): number => {
  if (price < currentMin) return price;
  else return currentMin;
};

/**
 * Verifica e retorna o maior pre칞o
 */
const checkMaxPrice = (price: number, currentMax: number): number => {
  if (price > currentMax) return price;
  else return currentMax;
};

/**
 * Extrai o total de an칰ncios do dataLayer da p치gina
 * @param $ Inst칙ncia do Cheerio carregada com o HTML
 * @returns N칰mero total de an칰ncios ou null se n칚o encontrado
 */
const extractTotalOfAds = ($: cheerio.CheerioAPI): number | null => {
  try {
    const dataLayerScript = $('script[id="datalayer"]').text();
    if (!dataLayerScript) {
      return null;
    }

    // Extrair o JSON do dataLayer
    // O script cont칠m: window.dataLayer = window.dataLayer || []; dataLayer.push({...})
    // Precisamos extrair o objeto dentro do push()
    const pushIndex = dataLayerScript.indexOf('dataLayer.push(');
    if (pushIndex === -1) {
      return null;
    }

    // Encontrar o in칤cio do objeto JSON (primeira chave ap칩s push()
    const startIndex = dataLayerScript.indexOf('{', pushIndex);
    if (startIndex === -1) {
      return null;
    }

    // Encontrar o final do objeto JSON contando chaves abertas/fechadas
    let braceCount = 0;
    let endIndex = startIndex;
    for (let i = startIndex; i < dataLayerScript.length; i++) {
      if (dataLayerScript[i] === '{') braceCount++;
      if (dataLayerScript[i] === '}') braceCount--;
      if (braceCount === 0) {
        endIndex = i + 1;
        break;
      }
    }

    if (braceCount !== 0) {
      return null;
    }

    const jsonString = dataLayerScript.substring(startIndex, endIndex);
    const dataLayerData = JSON.parse(jsonString) as {
      page?: {
        detail?: {
          totalOfAds?: string | number;
        };
      };
    };
    const totalAdsValue = dataLayerData?.page?.detail?.totalOfAds;

    return totalAdsValue ? parseInt(String(totalAdsValue)) : null;
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    logger.debug('Could not extract totalOfAds from datalayer: ' + errorMessage);
    return null;
  }
};

// Exporta para TypeScript
export { scraper, scrapePage, urlAlreadySearched, setUrlParam, extractTotalOfAds };

// Mant칠m compatibilidade com require() CommonJS
module.exports = {
  scraper,
  scrapePage,
  urlAlreadySearched,
  setUrlParam,
  extractTotalOfAds,
};
